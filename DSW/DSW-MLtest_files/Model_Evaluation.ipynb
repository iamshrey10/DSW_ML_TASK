{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1WDY1F59L_NCsD7R8k8nzAbNVseXqxqUw",
      "authorship_tag": "ABX9TyP9YR/ldtbvgk7bTuiu+3wn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GouravMidya/DSW-MLtest/blob/main/Different_Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "cwWPjRM3MwP0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Code to check gpu availablitiy\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6H6xUlMPfLj",
        "outputId": "cf333999-7ff7-4d5d-cd4d-35d740318d30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data (replace with actual file path)\n",
        "data = pd.read_excel('/content/drive/MyDrive/DSW Assessment/train_data.xlsx')\n"
      ],
      "metadata": {
        "id": "dZALLGxlM0WH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_data(data):\n",
        "    # Extract year and month from transaction_date\n",
        "    data['transaction_date'] = pd.to_datetime(data['transaction_date'])\n",
        "    data['transaction_year'] = data['transaction_date'].dt.year\n",
        "    data['transaction_month'] = data['transaction_date'].dt.month\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    data = data.drop(['customer_id', 'transaction_date'], axis=1)\n",
        "\n",
        "    # Handle categorical data\n",
        "    label_encoders = {}\n",
        "    categorical_cols = ['sub_grade', 'term', 'home_ownership', 'purpose', 'application_type', 'verification_status']\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        data[col] = le.fit_transform(data[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Scale numerical data\n",
        "    scaler = StandardScaler()\n",
        "    numerical_cols = ['cibil_score', 'total_no_of_acc', 'annual_inc', 'int_rate', 'loan_amnt', 'installment', 'account_bal', 'emp_length', 'transaction_year', 'transaction_month']\n",
        "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "    return data, label_encoders, scaler\n",
        "\n",
        "# Preprocess the data\n",
        "data, label_encoders, scaler = preprocess_data(data)\n",
        "\n",
        "# Split data into features and target\n",
        "X = data.drop('loan_status', axis=1)\n",
        "y = data['loan_status']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Models to evaluate\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "}\n",
        "\n",
        "# Evaluate models\n",
        "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
        "    results = {}\n",
        "\n",
        "    for name, model in tqdm(models.items(), desc=\"Evaluating models\"):\n",
        "        print(f\"\\nEvaluating {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Collect evaluation metrics\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "        results[name] = report\n",
        "\n",
        "        print(f\"Confusion Matrix for {name}:\\\n",
        "        {confusion_matrix(y_test, y_pred)}\")\n",
        "        print(f\"Classification Report for {name}:\\\n",
        "        {classification_report(y_test, y_pred)}\")\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "BRQJecEyNZQz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add ANN model\n",
        "def build_ann(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_dim=input_dim),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train and evaluate ANN\n",
        "ann_model = build_ann(X_train.shape[1])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "ann_history = ann_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=256,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "62pHygr2Nyi4",
        "outputId": "1ac25b09-5941-49c8-e9ce-4fd206c138b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7107 - loss: 0.6217 - val_accuracy: 0.7563 - val_loss: 0.5158\n",
            "Epoch 2/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7488 - loss: 0.5269 - val_accuracy: 0.7610 - val_loss: 0.5070\n",
            "Epoch 3/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7560 - loss: 0.5183 - val_accuracy: 0.7641 - val_loss: 0.5028\n",
            "Epoch 4/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7592 - loss: 0.5103 - val_accuracy: 0.7634 - val_loss: 0.5018\n",
            "Epoch 5/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7615 - loss: 0.5083 - val_accuracy: 0.7660 - val_loss: 0.4999\n",
            "Epoch 6/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7600 - loss: 0.5099 - val_accuracy: 0.7636 - val_loss: 0.5007\n",
            "Epoch 7/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.5045 - val_accuracy: 0.7666 - val_loss: 0.4992\n",
            "Epoch 8/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7635 - loss: 0.5067 - val_accuracy: 0.7671 - val_loss: 0.4992\n",
            "Epoch 9/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7645 - loss: 0.5051 - val_accuracy: 0.7677 - val_loss: 0.4987\n",
            "Epoch 10/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7634 - loss: 0.5041 - val_accuracy: 0.7670 - val_loss: 0.4984\n",
            "Epoch 11/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 0.5047 - val_accuracy: 0.7678 - val_loss: 0.4989\n",
            "Epoch 12/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7629 - loss: 0.5043 - val_accuracy: 0.7660 - val_loss: 0.5001\n",
            "Epoch 13/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7642 - loss: 0.5024 - val_accuracy: 0.7671 - val_loss: 0.4988\n",
            "Epoch 14/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7638 - loss: 0.5047 - val_accuracy: 0.7678 - val_loss: 0.4981\n",
            "Epoch 15/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7641 - loss: 0.5028 - val_accuracy: 0.7685 - val_loss: 0.4978\n",
            "Epoch 16/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7645 - loss: 0.5033 - val_accuracy: 0.7680 - val_loss: 0.4978\n",
            "Epoch 17/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7632 - loss: 0.5014 - val_accuracy: 0.7671 - val_loss: 0.4976\n",
            "Epoch 18/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.5025 - val_accuracy: 0.7684 - val_loss: 0.4986\n",
            "Epoch 19/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.5025 - val_accuracy: 0.7663 - val_loss: 0.4979\n",
            "Epoch 20/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7656 - loss: 0.4982 - val_accuracy: 0.7680 - val_loss: 0.4981\n",
            "Epoch 21/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7676 - loss: 0.4991 - val_accuracy: 0.7661 - val_loss: 0.4982\n",
            "Epoch 22/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7668 - loss: 0.4991 - val_accuracy: 0.7672 - val_loss: 0.4974\n",
            "Epoch 23/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7690 - loss: 0.4985 - val_accuracy: 0.7677 - val_loss: 0.4981\n",
            "Epoch 24/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7660 - loss: 0.5001 - val_accuracy: 0.7673 - val_loss: 0.4983\n",
            "Epoch 25/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.5002 - val_accuracy: 0.7669 - val_loss: 0.4977\n",
            "Epoch 26/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7641 - loss: 0.5017 - val_accuracy: 0.7673 - val_loss: 0.4980\n",
            "Epoch 27/50\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7661 - loss: 0.4995 - val_accuracy: 0.7672 - val_loss: 0.4979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate ANN\n",
        "ann_eval = ann_model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"\\nANN Model Accuracy: {ann_eval[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u2n6RRkOHWw",
        "outputId": "2a381f7f-f90c-4c66-97c2-c9804b063316"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.4980\n",
            "\n",
            "ANN Model Accuracy: 0.7680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQajfQK0MrZw",
        "outputId": "e6278219-3956-4ea9-e464-d27798757d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating models:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating models:  25%|██▌       | 1/4 [00:00<00:01,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Logistic Regression:        [[ 1551  4366]\n",
            " [  977 15847]]\n",
            "Classification Report for Logistic Regression:                      precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.26      0.37      5917\n",
            "           1       0.78      0.94      0.86     16824\n",
            "\n",
            "    accuracy                           0.77     22741\n",
            "   macro avg       0.70      0.60      0.61     22741\n",
            "weighted avg       0.74      0.77      0.73     22741\n",
            "\n",
            "\n",
            "Evaluating Random Forest...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating models:  50%|█████     | 2/4 [00:23<00:27, 13.83s/it]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [15:22:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Evaluating models:  75%|███████▌  | 3/4 [00:24<00:08,  8.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Random Forest:        [[ 1806  4111]\n",
            " [ 1229 15595]]\n",
            "Classification Report for Random Forest:                      precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.31      0.40      5917\n",
            "           1       0.79      0.93      0.85     16824\n",
            "\n",
            "    accuracy                           0.77     22741\n",
            "   macro avg       0.69      0.62      0.63     22741\n",
            "weighted avg       0.74      0.77      0.74     22741\n",
            "\n",
            "\n",
            "Evaluating XGBoost...\n",
            "Confusion Matrix for XGBoost:        [[ 1814  4103]\n",
            " [ 1267 15557]]\n",
            "Classification Report for XGBoost:                      precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.31      0.40      5917\n",
            "           1       0.79      0.92      0.85     16824\n",
            "\n",
            "    accuracy                           0.76     22741\n",
            "   macro avg       0.69      0.62      0.63     22741\n",
            "weighted avg       0.74      0.76      0.74     22741\n",
            "\n",
            "\n",
            "Evaluating Decision Tree...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating models: 100%|██████████| 4/4 [00:26<00:00,  6.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Decision Tree:        [[ 2391  3526]\n",
            " [ 3916 12908]]\n",
            "Classification Report for Decision Tree:                      precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.40      0.39      5917\n",
            "           1       0.79      0.77      0.78     16824\n",
            "\n",
            "    accuracy                           0.67     22741\n",
            "   macro avg       0.58      0.59      0.58     22741\n",
            "weighted avg       0.68      0.67      0.68     22741\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation\n",
        "results = evaluate_models(models, X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print summary\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name}: Accuracy: {metrics['accuracy']:.4f}, Precision (0): {metrics['0']['precision']:.4f}, Recall (0): {metrics['0']['recall']:.4f}, F1-Score (0): {metrics['0']['f1-score']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO_KUtlWPHhX",
        "outputId": "b6eb6df2-73fc-4458-c863-b2c48f877372"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: Accuracy: 0.7650, Precision (0): 0.6135, Recall (0): 0.2621, F1-Score (0): 0.3673\n",
            "Random Forest: Accuracy: 0.7652, Precision (0): 0.5951, Recall (0): 0.3052, F1-Score (0): 0.4035\n",
            "XGBoost: Accuracy: 0.7639, Precision (0): 0.5888, Recall (0): 0.3066, F1-Score (0): 0.4032\n",
            "Decision Tree: Accuracy: 0.6727, Precision (0): 0.3791, Recall (0): 0.4041, F1-Score (0): 0.3912\n"
          ]
        }
      ]
    }
  ]
}